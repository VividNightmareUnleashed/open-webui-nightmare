"""
title: Pro Mode
id: switch_model_action
author: Open WebUI Developer Toolkit
type: action
description: Regenerate the response using a pro model.
git_url: https://github.com/jrkropp/open-webui-developer-toolkit.git
required_open_webui_version: 0.6.10
version: 0.2.2
icon_url: data:image/svg+xml;base64,<svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 shrink-0" color="primary"><path d="M3.57746 9.14006L4.04387 9.61406C4.17091 9.48906 4.24246 9.31829 4.24246 9.14006C4.24246 8.96183 4.17091 8.79106 4.04387 8.66605L3.57746 9.14006ZM5.15265 5.1067L5.24716 5.76495C5.576 5.71774 5.81955 5.43508 5.81764 5.10288L5.15265 5.1067ZM5.15249 5.07797H4.48747L4.4875 5.08179L5.15249 5.07797ZM14.8475 5.07797L15.5125 5.08179V5.07797H14.8475ZM14.8473 5.1067L14.1824 5.10288C14.1805 5.43509 14.424 5.71774 14.7528 5.76495L14.8473 5.1067ZM16.4225 9.14006L15.9561 8.66605C15.8291 8.79106 15.7575 8.96183 15.7575 9.14006C15.7575 9.31829 15.8291 9.48906 15.9561 9.61406L16.4225 9.14006ZM15.4449 14.6301L15.2085 14.0085C14.9942 14.09 14.837 14.2762 14.7925 14.5011L15.4449 14.6301ZM4.5551 14.6301L5.20748 14.5011C5.16302 14.2762 5.00581 14.09 4.79149 14.0085L4.5551 14.6301ZM3.08743 8.71947C2.82511 8.97653 2.82084 9.39756 3.07789 9.65988C3.33494 9.9222 3.75597 9.92647 4.01829 9.66941L3.08743 8.71947ZM5.52606 9.05389C5.89333 9.05389 6.19106 8.75616 6.19106 8.38889C6.19106 8.02162 5.89333 7.72389 5.52606 7.72389V9.05389ZM9.53457 10.3306C9.27225 10.5876 9.26798 11.0087 9.52503 11.271C9.78208 11.5333 10.2031 11.5376 10.4654 11.2805L9.53457 10.3306ZM11.9732 10.665C12.3405 10.665 12.6382 10.3673 12.6382 10C12.6382 9.63273 12.3405 9.335 11.9732 9.335V10.665ZM17.9123 12.0141C17.9123 11.6468 17.6146 11.3491 17.2473 11.3491C16.88 11.3491 16.5823 11.6468 16.5823 12.0141H17.9123ZM13.5049 13.9616C13.1731 13.804 12.7765 13.9451 12.6189 14.2769C12.4613 14.6086 12.6024 15.0053 12.9342 15.1629L13.5049 13.9616ZM7.86868 11.5445C7.53694 11.3869 7.14026 11.5281 6.98267 11.8598C6.82507 12.1915 6.96625 12.5882 7.29799 12.7458L7.86868 11.5445ZM10.2853 12.7458C10.6171 12.5882 10.7583 12.1915 10.6007 11.8598C10.4431 11.5281 10.0464 11.3869 9.71465 11.5445L10.2853 12.7458ZM8.10085 6.17688C7.76911 6.33448 7.62793 6.73116 7.78552 7.0629C7.94312 7.39464 8.3398 7.53581 8.67154 7.37822L8.10085 6.17688ZM9.59453 7.17123C9.96179 7.17123 10.2595 6.8735 10.2595 6.50623C10.2595 6.13896 9.96179 5.84123 9.59453 5.84123V7.17123ZM15.4994 5.16667C15.4994 4.7994 15.2017 4.50167 14.8344 4.50167C14.4671 4.50167 14.1694 4.7994 14.1694 5.16667H15.4994ZM13.1888 6.7401C12.8592 6.90206 12.7232 7.30057 12.8852 7.6302C13.0472 7.95983 13.4457 8.09576 13.7753 7.9338L13.1888 6.7401ZM5.15249 5.07797L4.4875 5.08179L4.48766 5.11052L5.15265 5.1067L5.81764 5.10288L5.81747 5.07414L5.15249 5.07797ZM14.8473 5.1067L15.5123 5.11052L15.5125 5.08179L14.8475 5.07797L14.1825 5.07415L14.1824 5.10288L14.8473 5.1067ZM10 5.14295H9.335V14.8441H10H10.665V5.14295H10ZM4.5551 14.6301L3.90272 14.759C4.25542 16.5436 5.64061 17.7324 7.12679 17.8958C7.8764 17.9783 8.6507 17.7972 9.29938 17.2972C9.94755 16.7975 10.4211 16.0184 10.6493 14.9879L10 14.8441L9.35073 14.7003C9.17613 15.4888 8.84234 15.9702 8.48741 16.2438C8.133 16.517 7.70844 16.6218 7.27219 16.5738C6.38665 16.4764 5.45217 15.7392 5.20748 14.5011L4.5551 14.6301ZM10 14.8441L9.35073 14.9879C9.57891 16.0184 10.0524 16.7975 10.7006 17.2972C11.3493 17.7972 12.1236 17.9783 12.8732 17.8958C14.3594 17.7324 15.7446 16.5436 16.0973 14.759L15.4449 14.6301L14.7925 14.5011C14.5478 15.7392 13.6134 16.4764 12.7278 16.5738C12.2916 16.6218 11.867 16.517 11.5126 16.2438C11.1577 15.9702 10.8239 15.4888 10.6493 14.7003L10 14.8441ZM3.57746 9.14006L3.11104 8.66605C2.18352 9.57872 1.94758 11.0213 2.15576 12.2555C2.36354 13.4874 3.06106 14.7733 4.31871 15.2516L4.5551 14.6301L4.79149 14.0085C4.14378 13.7622 3.63213 13.0119 3.46724 12.0343C3.30276 11.0592 3.53068 10.119 4.04387 9.61406L3.57746 9.14006ZM5.15265 5.1067L5.05814 4.44845C3.73273 4.63874 2.69968 5.36578 2.28207 6.39936C1.85523 7.45578 2.14106 8.65961 3.11104 9.61406L3.57746 9.14006L4.04387 8.66605C3.39282 8.02542 3.32155 7.37692 3.51521 6.89761C3.71811 6.39545 4.28317 5.90335 5.24716 5.76495L5.15265 5.1067ZM16.4225 9.14006L16.889 9.61406C17.8589 8.65961 18.1448 7.45578 17.7179 6.39936C17.3003 5.36578 16.2673 4.63874 14.9419 4.44845L14.8473 5.1067L14.7528 5.76495C15.7168 5.90335 16.2819 6.39545 16.4848 6.89761C16.6785 7.37692 16.6072 8.02542 15.9561 8.66605L16.4225 9.14006ZM15.4449 14.6301L15.6813 15.2516C16.9389 14.7733 17.6365 13.4874 17.8442 12.2556C18.0524 11.0213 17.8165 9.57872 16.889 8.66605L16.4225 9.14006L15.9561 9.61406C16.4693 10.119 16.6972 11.0592 16.5328 12.0343C16.3679 13.0119 15.8562 13.7622 15.2085 14.0085L15.4449 14.6301ZM14.8475 5.07797H15.5125C15.5125 4.10684 15.1294 3.33433 14.5217 2.81587C13.9281 2.30941 13.1595 2.07735 12.4167 2.08519C11.6737 2.09304 10.9081 2.34139 10.3186 2.85899C9.71615 3.38803 9.335 4.16711 9.335 5.14295H10H10.665C10.665 4.53836 10.8898 4.12744 11.1962 3.85839C11.5156 3.57791 11.962 3.42007 12.4308 3.41512C12.8999 3.41017 13.3432 3.55869 13.6585 3.82767C13.9597 4.08466 14.1825 4.48245 14.1825 5.07797H14.8475ZM10 5.14295H10.665C10.665 4.16711 10.2839 3.38803 9.68135 2.85899C9.09187 2.34138 8.32633 2.09304 7.58327 2.08519C6.84051 2.07735 6.07193 2.30941 5.4783 2.81587C4.87061 3.33433 4.48749 4.10684 4.48749 5.07797H5.15249H5.81749C5.81749 4.48245 6.0403 4.08466 6.34152 3.82767C6.6568 3.55869 7.1001 3.41016 7.56922 3.41512C8.03803 3.42007 8.48437 3.57791 8.8038 3.85839C9.11021 4.12744 9.335 4.53836 9.335 5.14295H10ZM3.55286 9.19444L4.01829 9.66941C4.40755 9.28797 4.93881 9.05389 5.52606 9.05389V8.38889V7.72389C4.57687 7.72389 3.71521 8.1043 3.08743 8.71947L3.55286 9.19444ZM10 10.8056L10.4654 11.2805C10.8547 10.8991 11.3859 10.665 11.9732 10.665V10V9.335C11.024 9.335 10.1624 9.71541 9.53457 10.3306L10 10.8056ZM17.2473 12.0141H16.5823C16.5823 13.204 15.6177 14.1686 14.4279 14.1686V14.8336V15.4986C16.3523 15.4986 17.9123 13.9385 17.9123 12.0141H17.2473ZM14.4279 14.8336V14.1686C14.0962 14.1686 13.7838 14.0941 13.5049 13.9616L13.2195 14.5622L12.9342 15.1629C13.3877 15.3783 13.8947 15.4986 14.4279 15.4986V14.8336ZM8.79167 12.4165V11.7515C8.46002 11.7515 8.14763 11.677 7.86868 11.5445L7.58333 12.1452L7.29799 12.7458C7.75149 12.9613 8.25847 13.0815 8.79167 13.0815V12.4165ZM10 12.1452L9.71465 11.5445C9.4357 11.677 9.12331 11.7515 8.79167 11.7515V12.4165V13.0815C9.32487 13.0815 9.83184 12.9613 10.2853 12.7458L10 12.1452ZM8.38619 6.77755L8.67154 7.37822C8.95049 7.24571 9.26288 7.17123 9.59453 7.17123V6.50623V5.84123C9.06133 5.84123 8.55435 5.96145 8.10085 6.17688L8.38619 6.77755ZM14.8344 5.16667H14.1694C14.1694 5.85626 13.771 6.45405 13.1888 6.7401L13.482 7.33695L13.7753 7.9338C14.7951 7.43272 15.4994 6.38256 15.4994 5.16667H14.8344Z" fill="currentColor"></path></svg>

"""

from __future__ import annotations
import inspect
import logging
from typing import Any, Awaitable, Callable, Optional
from fastapi import Request
from pydantic import BaseModel, Field

# Import Open WebUI utilities for loading function modules
from open_webui.utils.plugin import get_function_module_from_cache
from open_webui.models.functions import Functions


class Action:
    class Valves(BaseModel):
        TARGET_MODEL: str = Field(
            default="openai_responses.gpt-5-thinking-high",
            description="The model to switch to (use full manifold model ID, e.g., 'openai_responses.gpt-5-thinking-high')"
        )
        MANIFOLD_ID: str = Field(
            default="openai_responses",
            description="The ID of the manifold pipe to invoke (default: openai_responses)"
        )
        DEBUG: bool = Field(
            default=False,
            description="Show debug information in notifications (useful when troubleshooting)"
        )

    def __init__(self) -> None:
        self.valves = self.Valves()
        self.logger = logging.getLogger(__name__)

    async def action(
        self,
        body: dict,
        __user__: dict,
        __request__: Request,
        __event_emitter__: Callable[[dict[str, Any]], Awaitable[None]],
        __event_call__: Optional[Callable[[dict[str, Any]], Awaitable[Any]]] = None,
        __metadata__: Optional[dict] = None,
        __tools__: Optional[list | dict] = None,
        __task__: Optional[dict] = None,
        __task_body__: Optional[dict] = None,
    ) -> dict:
        """
        Action: Switch to pro model and regenerate the response.

        This action invokes the OpenAI Responses Manifold directly, ensuring
        all manifold logic (reasoning_effort, text.verbosity, service_tier)
        and active filters (Extended Thinking, Verbose, Priority) are respected.
        """
        manifold_id = self.valves.MANIFOLD_ID
        target_model = self.valves.TARGET_MODEL

        # 1. Load the manifold module from cache
        try:
            manifold_module, _, _ = get_function_module_from_cache(__request__, manifold_id)
        except Exception as e:
            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": f"Failed to load manifold '{manifold_id}': {e}"
                }
            })
            return {"content": f"Error: Could not load manifold '{manifold_id}'"}

        # 2. Load and set manifold valves from database
        if hasattr(manifold_module, "valves") and hasattr(manifold_module, "Valves"):
            try:
                valves = Functions.get_function_valves_by_id(manifold_id)
                manifold_module.valves = manifold_module.Valves(**(valves if valves else {}))
            except Exception as e:
                await __event_emitter__({
                    "type": "notification",
                    "data": {
                        "type": "error",
                        "content": f"Failed to load manifold valves: {e}"
                    }
                })
                return {"content": f"Error: Could not load manifold valves"}

        # 3. Change model to target pro model
        body["model"] = target_model

        # 3a. Ensure stream is set (required by manifold)
        if "stream" not in body:
            body["stream"] = True

        # 3b. CRITICAL FIX: Update metadata to match new model
        # The manifold uses __metadata__["model"]["id"] to fetch conversation history
        # and apply model-specific logic. It MUST match body["model"].
        if __metadata__ is None:
            __metadata__ = {}
        if "model" not in __metadata__:
            __metadata__["model"] = {}
        __metadata__["model"]["id"] = target_model

        # 3b. Verify body has required fields
        if "messages" not in body or not body.get("messages"):
            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": "Invalid request: no messages found"
                }
            })
            return {"content": "Error: No messages in request body"}

        # 3c. Debug logging and notification
        self.logger.info("Pro Mode Action Debug:")
        self.logger.info(f"  Target Model: {target_model}")
        self.logger.info(f"  Body Model: {body.get('model')}")
        self.logger.info(f"  Metadata Model: {__metadata__.get('model', {}).get('id')}")
        self.logger.info(f"  Message Count: {len(body.get('messages', []))}")
        self.logger.info(f"  Stream: {body.get('stream', 'not set')}")
        self.logger.info(f"  Chat ID: {__metadata__.get('chat_id', 'not set')}")

        # Show debug info in notification if DEBUG valve is enabled
        if self.valves.DEBUG:
            import json
            debug_info = {
                "target_model": target_model,
                "body_model": body.get("model"),
                "metadata_model": __metadata__.get("model", {}).get("id"),
                "message_count": len(body.get("messages", [])),
                "stream": body.get("stream"),
                "chat_id": __metadata__.get("chat_id"),
                "body_keys": list(body.keys()),
            }
            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "info",
                    "content": f"Debug Info:\n{json.dumps(debug_info, indent=2)}"
                }
            })

        # 4. Show minimal status feedback
        await __event_emitter__({
            "type": "status",
            "data": {
                "description": "Pro Mode",
                "done": True
            }
        })

        # 5. Call manifold's pipe method with all parameters
        try:
            result = await manifold_module.pipe(
                body=body,
                __user__=__user__,
                __request__=__request__,
                __event_emitter__=__event_emitter__,
                __metadata__=__metadata__ or {},
                __tools__=__tools__,
                __task__=__task__,
                __task_body__=__task_body__,
                __event_call__=__event_call__,
            )
        except Exception as e:
            # Log detailed error information
            self.logger.error(f"Pro Mode Action Error: {e}")
            self.logger.error(f"Error type: {type(e).__name__}")

            # Try to extract more details from aiohttp errors
            error_detail = str(e)
            if hasattr(e, 'status'):
                self.logger.error(f"HTTP Status: {e.status}")
            if hasattr(e, 'message'):
                self.logger.error(f"HTTP Message: {e.message}")
            if hasattr(e, 'headers'):
                self.logger.error(f"Response Headers: {e.headers}")

            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": f"Failed to generate response: {error_detail}"
                }
            })
            return {"content": f"Error: {error_detail}"}

        # 6. Handle streaming or non-streaming response
        if inspect.isasyncgen(result):
            # Streaming: collect all chunks
            full_response = ""
            try:
                async for chunk in result:
                    full_response += str(chunk)
            except Exception as e:
                await __event_emitter__({
                    "type": "notification",
                    "data": {
                        "type": "error",
                        "content": f"Streaming error: {e}"
                    }
                })
                return {"content": full_response or f"Error during streaming: {e}"}

            return {"content": full_response}
        elif isinstance(result, str):
            # Non-streaming: return directly
            return {"content": result}
        else:
            # Unexpected result type
            return {"content": ""}
