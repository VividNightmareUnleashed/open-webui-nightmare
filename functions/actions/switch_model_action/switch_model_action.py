"""
title: Pro Mode
id: switch_model_action
author: Open WebUI Developer Toolkit
type: action
description: Regenerate the response using a pro model with full conversation context.
git_url: https://github.com/jrkropp/open-webui-developer-toolkit.git
required_open_webui_version: 0.6.10
version: 0.4.2
icon_url: data:image/svg+xml;base64,<svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg" class="h-5 w-5 shrink-0" color="primary"><path d="M3.57746 9.14006L4.04387 9.61406C4.17091 9.48906 4.24246 9.31829 4.24246 9.14006C4.24246 8.96183 4.17091 8.79106 4.04387 8.66605L3.57746 9.14006ZM5.15265 5.1067L5.24716 5.76495C5.576 5.71774 5.81955 5.43508 5.81764 5.10288L5.15265 5.1067ZM5.15249 5.07797H4.48747L4.4875 5.08179L5.15249 5.07797ZM14.8475 5.07797L15.5125 5.08179V5.07797H14.8475ZM14.8473 5.1067L14.1824 5.10288C14.1805 5.43509 14.424 5.71774 14.7528 5.76495L14.8473 5.1067ZM16.4225 9.14006L15.9561 8.66605C15.8291 8.79106 15.7575 8.96183 15.7575 9.14006C15.7575 9.31829 15.8291 9.48906 15.9561 9.61406L16.4225 9.14006ZM15.4449 14.6301L15.2085 14.0085C14.9942 14.09 14.837 14.2762 14.7925 14.5011L15.4449 14.6301ZM4.5551 14.6301L5.20748 14.5011C5.16302 14.2762 5.00581 14.09 4.79149 14.0085L4.5551 14.6301ZM3.08743 8.71947C2.82511 8.97653 2.82084 9.39756 3.07789 9.65988C3.33494 9.9222 3.75597 9.92647 4.01829 9.66941L3.08743 8.71947ZM5.52606 9.05389C5.89333 9.05389 6.19106 8.75616 6.19106 8.38889C6.19106 8.02162 5.89333 7.72389 5.52606 7.72389V9.05389ZM9.53457 10.3306C9.27225 10.5876 9.26798 11.0087 9.52503 11.271C9.78208 11.5333 10.2031 11.5376 10.4654 11.2805L9.53457 10.3306ZM11.9732 10.665C12.3405 10.665 12.6382 10.3673 12.6382 10C12.6382 9.63273 12.3405 9.335 11.9732 9.335V10.665ZM17.9123 12.0141C17.9123 11.6468 17.6146 11.3491 17.2473 11.3491C16.88 11.3491 16.5823 11.6468 16.5823 12.0141H17.9123ZM13.5049 13.9616C13.1731 13.804 12.7765 13.9451 12.6189 14.2769C12.4613 14.6086 12.6024 15.0053 12.9342 15.1629L13.5049 13.9616ZM7.86868 11.5445C7.53694 11.3869 7.14026 11.5281 6.98267 11.8598C6.82507 12.1915 6.96625 12.5882 7.29799 12.7458L7.86868 11.5445ZM10.2853 12.7458C10.6171 12.5882 10.7583 12.1915 10.6007 11.8598C10.4431 11.5281 10.0464 11.3869 9.71465 11.5445L10.2853 12.7458ZM8.10085 6.17688C7.76911 6.33448 7.62793 6.73116 7.78552 7.0629C7.94312 7.39464 8.3398 7.53581 8.67154 7.37822L8.10085 6.17688ZM9.59453 7.17123C9.96179 7.17123 10.2595 6.8735 10.2595 6.50623C10.2595 6.13896 9.96179 5.84123 9.59453 5.84123V7.17123ZM15.4994 5.16667C15.4994 4.7994 15.2017 4.50167 14.8344 4.50167C14.4671 4.50167 14.1694 4.7994 14.1694 5.16667H15.4994ZM13.1888 6.7401C12.8592 6.90206 12.7232 7.30057 12.8852 7.6302C13.0472 7.95983 13.4457 8.09576 13.7753 7.9338L13.1888 6.7401ZM5.15249 5.07797L4.4875 5.08179L4.48766 5.11052L5.15265 5.1067L5.81764 5.10288L5.81747 5.07414L5.15249 5.07797ZM14.8473 5.1067L15.5123 5.11052L15.5125 5.08179L14.8475 5.07797L14.1825 5.07415L14.1824 5.10288L14.8473 5.1067ZM10 5.14295H9.335V14.8441H10H10.665V5.14295H10ZM4.5551 14.6301L3.90272 14.759C4.25542 16.5436 5.64061 17.7324 7.12679 17.8958C7.8764 17.9783 8.6507 17.7972 9.29938 17.2972C9.94755 16.7975 10.4211 16.0184 10.6493 14.9879L10 14.8441L9.35073 14.7003C9.17613 15.4888 8.84234 15.9702 8.48741 16.2438C8.133 16.517 7.70844 16.6218 7.27219 16.5738C6.38665 16.4764 5.45217 15.7392 5.20748 14.5011L4.5551 14.6301ZM10 14.8441L9.35073 14.9879C9.57891 16.0184 10.0524 16.7975 10.7006 17.2972C11.3493 17.7972 12.1236 17.9783 12.8732 17.8958C14.3594 17.7324 15.7446 16.5436 16.0973 14.759L15.4449 14.6301L14.7925 14.5011C14.5478 15.7392 13.6134 16.4764 12.7278 16.5738C12.2916 16.6218 11.867 16.517 11.5126 16.2438C11.1577 15.9702 10.8239 15.4888 10.6493 14.7003L10 14.8441ZM3.57746 9.14006L3.11104 8.66605C2.18352 9.57872 1.94758 11.0213 2.15576 12.2555C2.36354 13.4874 3.06106 14.7733 4.31871 15.2516L4.5551 14.6301L4.79149 14.0085C4.14378 13.7622 3.63213 13.0119 3.46724 12.0343C3.30276 11.0592 3.53068 10.119 4.04387 9.61406L3.57746 9.14006ZM5.15265 5.1067L5.05814 4.44845C3.73273 4.63874 2.69968 5.36578 2.28207 6.39936C1.85523 7.45578 2.14106 8.65961 3.11104 9.61406L3.57746 9.14006L4.04387 8.66605C3.39282 8.02542 3.32155 7.37692 3.51521 6.89761C3.71811 6.39545 4.28317 5.90335 5.24716 5.76495L5.15265 5.1067ZM16.4225 9.14006L16.889 9.61406C17.8589 8.65961 18.1448 7.45578 17.7179 6.39936C17.3003 5.36578 16.2673 4.63874 14.9419 4.44845L14.8473 5.1067L14.7528 5.76495C15.7168 5.90335 16.2819 6.39545 16.4848 6.89761C16.6785 7.37692 16.6072 8.02542 15.9561 8.66605L16.4225 9.14006ZM15.4449 14.6301L15.6813 15.2516C16.9389 14.7733 17.6365 13.4874 17.8442 12.2556C18.0524 11.0213 17.8165 9.57872 16.889 8.66605L16.4225 9.14006L15.9561 9.61406C16.4693 10.119 16.6972 11.0592 16.5328 12.0343C16.3679 13.0119 15.8562 13.7622 15.2085 14.0085L15.4449 14.6301ZM14.8475 5.07797H15.5125C15.5125 4.10684 15.1294 3.33433 14.5217 2.81587C13.9281 2.30941 13.1595 2.07735 12.4167 2.08519C11.6737 2.09304 10.9081 2.34139 10.3186 2.85899C9.71615 3.38803 9.335 4.16711 9.335 5.14295H10H10.665C10.665 4.53836 10.8898 4.12744 11.1962 3.85839C11.5156 3.57791 11.962 3.42007 12.4308 3.41512C12.8999 3.41017 13.3432 3.55869 13.6585 3.82767C13.9597 4.08466 14.1825 4.48245 14.1825 5.07797H14.8475ZM10 5.14295H10.665C10.665 4.16711 10.2839 3.38803 9.68135 2.85899C9.09187 2.34138 8.32633 2.09304 7.58327 2.08519C6.84051 2.07735 6.07193 2.30941 5.4783 2.81587C4.87061 3.33433 4.48749 4.10684 4.48749 5.07797H5.15249H5.81749C5.81749 4.48245 6.0403 4.08466 6.34152 3.82767C6.6568 3.55869 7.1001 3.41016 7.56922 3.41512C8.03803 3.42007 8.48437 3.57791 8.8038 3.85839C9.11021 4.12744 9.335 4.53836 9.335 5.14295H10ZM3.55286 9.19444L4.01829 9.66941C4.40755 9.28797 4.93881 9.05389 5.52606 9.05389V8.38889V7.72389C4.57687 7.72389 3.71521 8.1043 3.08743 8.71947L3.55286 9.19444ZM10 10.8056L10.4654 11.2805C10.8547 10.8991 11.3859 10.665 11.9732 10.665V10V9.335C11.024 9.335 10.1624 9.71541 9.53457 10.3306L10 10.8056ZM17.2473 12.0141H16.5823C16.5823 13.204 15.6177 14.1686 14.4279 14.1686V14.8336V15.4986C16.3523 15.4986 17.9123 13.9385 17.9123 12.0141H17.2473ZM14.4279 14.8336V14.1686C14.0962 14.1686 13.7838 14.0941 13.5049 13.9616L13.2195 14.5622L12.9342 15.1629C13.3877 15.3783 13.8947 15.4986 14.4279 15.4986V14.8336ZM8.79167 12.4165V11.7515C8.46002 11.7515 8.14763 11.677 7.86868 11.5445L7.58333 12.1452L7.29799 12.7458C7.75149 12.9613 8.25847 13.0815 8.79167 13.0815V12.4165ZM10 12.1452L9.71465 11.5445C9.4357 11.677 9.12331 11.7515 8.79167 11.7515V12.4165V13.0815C9.32487 13.0815 9.83184 12.9613 10.2853 12.7458L10 12.1452ZM8.38619 6.77755L8.67154 7.37822C8.95049 7.24571 9.26288 7.17123 9.59453 7.17123V6.50623V5.84123C9.06133 5.84123 8.55435 5.96145 8.10085 6.17688L8.38619 6.77755ZM14.8344 5.16667H14.1694C14.1694 5.85626 13.771 6.45405 13.1888 6.7401L13.482 7.33695L13.7753 7.9338C14.7951 7.43272 15.4994 6.38256 15.4994 5.16667H14.8344Z" fill="currentColor"></path></svg>

"""

from __future__ import annotations
import aiohttp
import json
import logging
import os
import re
from typing import Any, Awaitable, Callable, List, Optional
from pydantic import BaseModel, Field


class Action:
    class Valves(BaseModel):
        OPENAI_API_KEY: str = Field(
            default=os.getenv("OPENAI_API_KEY", ""),
            description="OpenAI API key (or set OPENAI_API_KEY environment variable)"
        )
        OPENAI_BASE_URL: str = Field(
            default="https://api.openai.com/v1",
            description="OpenAI API base URL"
        )
        TARGET_MODEL: str = Field(
            default="gpt-5",
            description="The model to switch to (e.g., 'gpt-5', 'gpt-4o', 'o3-mini')"
        )
        REASONING_EFFORT: str = Field(
            default="high",
            description="Reasoning effort level ('minimal', 'high', or leave empty for default). Only applies to reasoning models."
        )
        DEBUG: bool = Field(
            default=False,
            description="Show debug information in logs (useful when troubleshooting)"
        )

    def __init__(self) -> None:
        self.valves = self.Valves()
        self.logger = logging.getLogger(__name__)
        self.session: Optional[aiohttp.ClientSession] = None

    async def _get_or_create_session(self) -> aiohttp.ClientSession:
        """Get or create aiohttp session for API calls."""
        if self.session is None or self.session.closed:
            self.session = aiohttp.ClientSession()
        return self.session

    def build_conversation_input(self, messages: List[dict]) -> List[dict]:
        """
        Convert Open WebUI messages to OpenAI Responses API input format.

        Excludes the last assistant message (which is being regenerated).
        Strips system messages (they should go in 'instructions' parameter).
        Strips status blocks from assistant messages.
        """
        if self.valves.DEBUG:
            self.logger.debug(f"=== RAW MESSAGES RECEIVED (total: {len(messages)}) ===")
            for i, msg in enumerate(messages):
                self.logger.debug(f"Message {i}: role={msg.get('role')}, content_type={type(msg.get('content'))}")
                if isinstance(msg.get('content'), list):
                    for j, block in enumerate(msg.get('content', [])):
                        self.logger.debug(f"  Block {j}: {block.get('type')} - {list(block.keys())}")

        openai_input = []

        # Process all messages except the last one (which should be the assistant message being regenerated)
        for msg in messages[:-1]:
            role = msg.get("role")
            content = msg.get("content", "")

            # Skip system messages (they belong in 'instructions', not 'input')
            if role == "system":
                continue

            # User message
            elif role == "user":
                # Convert string content to a block list
                content_blocks = content or []
                if isinstance(content_blocks, str):
                    content_blocks = [{"type": "text", "text": content_blocks}]

                # Transform each block to Responses API format
                block_transform = {
                    "text":       lambda b: {"type": "input_text",  "text": b.get("text", "")},
                    "image_url":  lambda b: {"type": "input_image", "image_url": b.get("image_url", {}).get("url")},
                    "input_file": lambda b: {"type": "input_file",  "file_id": b.get("file_id")},
                }

                openai_input.append({
                    "role": "user",
                    "content": [
                        block_transform.get(block.get("type"), lambda b: b)(block)
                        for block in content_blocks if block
                    ],
                })

            # Assistant message
            elif role == "assistant":
                # Strip <details> blocks and clean content
                clean_content = re.sub(r'<details[^>]*>.*?</details>', '', content, flags=re.DOTALL).strip()
                if clean_content:
                    openai_input.append({
                        "role": "assistant",
                        "content": [{"type": "output_text", "text": clean_content}]
                    })

        if self.valves.DEBUG:
            self.logger.debug(f"=== TRANSFORMED CONVERSATION INPUT (total: {len(openai_input)} messages) ===")
            for i, msg in enumerate(openai_input):
                self.logger.debug(f"Transformed {i}: role={msg.get('role')}")
                content_items = msg.get('content', [])
                if isinstance(content_items, list):
                    for j, item in enumerate(content_items):
                        item_type = item.get('type', 'unknown')
                        if item_type == 'input_image':
                            self.logger.debug(f"  Content {j}: {item_type} - URL length: {len(item.get('image_url', ''))}")
                        else:
                            self.logger.debug(f"  Content {j}: {item_type}")

        return openai_input

    async def action(
        self,
        body: dict,
        __user__: dict,
        __event_emitter__: Callable[[dict[str, Any]], Awaitable[None]],
        __event_call__: Optional[Callable[[dict[str, Any]], Awaitable[Any]]] = None,
    ) -> dict:
        """
        Action: Switch to pro model and regenerate the response.

        Makes a direct HTTP request to OpenAI Responses API with full conversation context.
        """
        # Validate API key
        if not self.valves.OPENAI_API_KEY:
            error_msg = "OPENAI_API_KEY is not set. Please configure it in the action valves or environment variables."
            self.logger.error(error_msg)
            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": error_msg
                }
            })
            # Modify body to show error
            for i in range(len(body.get("messages", [])) - 1, -1, -1):
                if body["messages"][i].get("role") == "assistant":
                    body["messages"][i]["content"] = f"Error: {error_msg}"
                    break
            return body

        # Get configuration
        model_name = self.valves.TARGET_MODEL
        reasoning_effort = self.valves.REASONING_EFFORT.strip()

        if self.valves.DEBUG:
            self.logger.info("=== PRO MODE ACTION ===")
            self.logger.info(f"Target model: {model_name}")
            self.logger.info(f"Reasoning effort: {reasoning_effort}")

        # Extract messages and convert to Responses API format
        messages = body.get("messages", [])
        if not messages:
            error_msg = "No messages found in request"
            self.logger.error(error_msg)
            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": error_msg
                }
            })
            return body  # Return body as-is if no messages

        # Convert conversation to Responses API format (includes full context)
        conversation_input = self.build_conversation_input(messages)

        if not conversation_input:
            error_msg = "No conversation context found"
            self.logger.error(error_msg)
            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": error_msg
                }
            })
            # Modify body to show error
            for i in range(len(body.get("messages", [])) - 1, -1, -1):
                if body["messages"][i].get("role") == "assistant":
                    body["messages"][i]["content"] = f"Error: {error_msg}"
                    break
            return body

        # Build Responses API request body with full conversation context
        request_body = {
            "model": model_name,
            "input": conversation_input,  # Full conversation history!
            "stream": False
        }

        # Add reasoning effort if specified
        if reasoning_effort:
            request_body["reasoning"] = {"effort": reasoning_effort}

        if self.valves.DEBUG:
            # Log summary of what's being sent
            self.logger.debug(f"=== FINAL REQUEST TO OPENAI ===")
            self.logger.debug(f"Model: {request_body.get('model')}")
            self.logger.debug(f"Input messages: {len(request_body.get('input', []))}")

            # Log details about images in the input
            for i, msg in enumerate(request_body.get('input', [])):
                content_list = msg.get('content', [])
                if isinstance(content_list, list):
                    image_count = sum(1 for item in content_list if item.get('type') == 'input_image')
                    text_count = sum(1 for item in content_list if item.get('type') == 'input_text')
                    if image_count > 0:
                        self.logger.debug(f"  Message {i} ({msg.get('role')}): {text_count} text blocks, {image_count} image(s)")

            # Full request body for detailed inspection
            self.logger.debug(f"Full request body: {json.dumps(request_body, indent=2)}")

        # Show status to user
        await __event_emitter__({
            "type": "status",
            "data": {
                "description": "Request for gpt-5 pro mode...",
                "done": False
            }
        })

        # Make API call to OpenAI Responses API
        try:
            session = await self._get_or_create_session()
            headers = {
                "Authorization": f"Bearer {self.valves.OPENAI_API_KEY}",
                "Content-Type": "application/json",
            }
            url = f"{self.valves.OPENAI_BASE_URL.rstrip('/')}/responses"

            async with session.post(url, json=request_body, headers=headers) as response:
                if response.status != 200:
                    error_text = await response.text()
                    error_msg = f"OpenAI API error (status {response.status}): {error_text}"
                    self.logger.error(error_msg)

                    await __event_emitter__({
                        "type": "status",
                        "data": {
                            "description": "Generation failed",
                            "done": True
                        }
                    })

                    await __event_emitter__({
                        "type": "notification",
                        "data": {
                            "type": "error",
                            "content": f"Failed to generate response: {error_text[:200]}"
                        }
                    })

                    # Modify body to show error
                    for i in range(len(body.get("messages", [])) - 1, -1, -1):
                        if body["messages"][i].get("role") == "assistant":
                            body["messages"][i]["content"] = f"Error: {error_text}"
                            break
                    return body

                response_data = await response.json()

                if self.valves.DEBUG:
                    self.logger.debug(f"Response data: {json.dumps(response_data, indent=2)}")

                # Extract content from Responses API response
                # Response structure: {"output": [{"type": "message", "content": [{"type": "output_text", "text": "..."}]}]}
                output = response_data.get("output", [])

                # Collect all text from message items
                content_parts = []
                for item in output:
                    if item.get("type") != "message":
                        continue
                    for content in item.get("content", []):
                        if content.get("type") == "output_text":
                            content_parts.append(content.get("text", ""))

                content_result = "\n".join(content_parts).strip()

                # Show completion status
                await __event_emitter__({
                    "type": "status",
                    "data": {
                        "description": "Generation complete",
                        "done": True
                    }
                })

                if not content_result:
                    error_msg = "No content in response from OpenAI"
                    self.logger.error(error_msg)
                    await __event_emitter__({
                        "type": "notification",
                        "data": {
                            "type": "error",
                            "content": error_msg
                        }
                    })
                    # Return error by modifying body
                    for i in range(len(body.get("messages", [])) - 1, -1, -1):
                        if body["messages"][i].get("role") == "assistant":
                            body["messages"][i]["content"] = f"Error: {error_msg}"
                            break
                    return body

                # Find the last assistant message and replace its content
                message_replaced = False
                for i in range(len(body.get("messages", [])) - 1, -1, -1):
                    if body["messages"][i].get("role") == "assistant":
                        body["messages"][i]["content"] = content_result
                        message_replaced = True
                        break

                if not message_replaced:
                    # No assistant message found, append new one
                    body["messages"].append({
                        "role": "assistant",
                        "content": content_result
                    })

                # Return the modified body (not just {"content": "..."})
                return body

        except Exception as e:
            error_msg = f"Failed to call OpenAI API: {str(e)}"
            self.logger.error(error_msg)
            self.logger.exception("Full error:")

            await __event_emitter__({
                "type": "status",
                "data": {
                    "description": "Generation failed",
                    "done": True
                }
            })

            await __event_emitter__({
                "type": "notification",
                "data": {
                    "type": "error",
                    "content": error_msg
                }
            })

            # Modify body to show error
            for i in range(len(body.get("messages", [])) - 1, -1, -1):
                if body["messages"][i].get("role") == "assistant":
                    body["messages"][i]["content"] = f"Error: {error_msg}"
                    break
            return body
